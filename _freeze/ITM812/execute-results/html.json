{
  "hash": "9f8131737c931b92cb64ee7abfda794f",
  "result": {
    "markdown": "---\ntitle: 머신러닝과 사업기회 - ITM812\ndate: last-modified\nauthor:\n  - name: Jiseok AHN\n    affiliation: KAIST\ntitle-block-banner: true\nformat:\n  html:\n    theme: flatly\n    code-fold: true\n    toc: true\n    toc-depth: 3\n    toc-title: 목차\n    number-sections: true\n    number-depth: 2\n    highlight-style: github\n    self-contained: false\nbibliography: references.bib\nfreeze: true\n---\n\n# Week 1\n\n## Intro\n\n-   30분만에 첫 강의 끝\n\n# Week 2\n\n## 과정 소개\n\n-   데이터가 많이 쌓이고, 선제적 의사결정 지원, Data-Driven Decision 중요\n\n-   질 좋은, 많은 데이터 활용 중요\n\n-   Data Exploration, Machine Learning 개념 및 실습, Internal/External Insight 발견, 프로세스의 효율적 개선과 경쟁력 향상을 위한 역량 향상 목표\n\n-   Python을 활용한 머신러닝 기반 데이터 분석 실습하고 실제 적용을 위한 모델링 수행\n\n-   Python 3를 기반으로 실습\n\n## 평가기준\n\n-   Term projects : 50%, Peer-review\n\n-   Mid Term : 30%,\n\n-   출석,참여도: 20%\n\n## 강의 구성\n\n-   Regression, Classification, etc.\n\n-   \n\n## Data Analytic (Machine Learning) Value\n\n-   정형/비정형 데이터\n\n-   정형 - 틀이 정해진. 나이, 키, 성별 등의 정보를 담는 데이터\n\n-   비정형 - 이미지, 언어, 소리, 컨설팅\n\n-   인간과 유사한 판단을 할 수 있도록 컴퓨터에게 학습을 시킨다. 적당한 반복을 할 수 있을 때, 이를 대체할 수 도록\n\n## Data -\\> Insight -\\> Value\n\n-   Analysis : 데이터마이닝, 머신러닝, 딥러닝\n\n-   Action: 의사결정자, 엔지니어, 마케터, 투자자, 인사관리자 등\n\n-   GPU vs CPU. 다윗과 골리앗. 무거운 걸 들을때 다윗 10명 \\<\\< 찐 골리앗 1명. 우표를 붙이는 작업을 할 때 다윗 10명 \\>\\> 골리앗 1명.\n\n    -   GPU는 반복작업을 위해 만들어진 것\n\n-   딥러닝은 머신러닝의 세부 단위?. 머신러닝을 잘 알면 딥러닝이 언제 필요한 지 알 수 있을 것\n\n## AI \\> Machine Learning \\> Deep Learning\n\n-   **AI**: 가장 큰 범주. 큰 범주 안에 머신러닝이 속하고, 머신러닝의 일부분이 딥러닝\n\n-   사람과 유사한 판단을 컴퓨터가 할 수 있게 끔 만드는 것이 **인공지능**\n\n-   기존의 데이터를 이용해 앞으로 일을 예측하는 **머신러닝**\n\n-   머신러닝 안에 여러 알고리즘 중 하나가 **딥러닝**\n\n-   **인공지능**이 먹을 수 있는 모든 음식이라면, **머신러닝**은 그 중 영양가가 많은 고기 음식, 딥러닝은 그 중에서도 최고급 스테이크 요리\n\n## Machine Learning vs. Programming\n\n-   전통적인 SW(프로그래밍)은 한번만 만들면 된다.\n\n-   ML(Machine Learning)은 전통적인 SW 개발과 달리, 데이터 학습을 통해 더 좋은 규칙을 계속 만들어 냄.\n\n-   하드웨어 성능이 좋을 수록, 계속 반복할 수록, 데이터가 많아질 수록 성능도 함께 발전.\n\n-   값을 주면 결과를 제시하는 게 프로그래밍, 데이터와 답을 주면 규칙을 내놓는 게 머신러닝.\n\n## 머신라닝의 세 가지 타입\n\n-   Supervised Learning 지도 학습\n\n    -   제일 많이 쓰임. 지도하다. 가이드하다. 명확하게 답이 있는 것. 정답(맞았다, 틀렸다 가능// TRUE OR FALSE). 라벨링.\n\n    -   **딥러닝**을 잘하라면 라벨링을 잘해야함. 딥러닝은 Classification 방법 중 하나. 방법론은 물론, 데이터 라벨링이 중요.\n\n-   Unsupervised Learning 비지도 학습\n\n    -   지도하지 않는다. 라벨링하지 않는다. 정답이 없다. 정답이 없으니 비슷한 것들끼리 그룹을 지어준다. Grouping-\\> Clustering. Similarity. Distance 기반.\n\n    -   Clustering. 비슷한 데에 모여있는 것들끼리. K-means, K-NN(Nearest Neighbor, 최근접 이웃)\n\n-   Reinforcement 강화 학습\n\n    -   정답은 없는데, 부족한 부분을 계속 학습하는 과정. 딥러닝으로 발전하는 것과 비슷함.\n\n-   딥러닝은 Supervised와 Reinforcement가 합쳐진 것이다.\n\n# Week 3\n\n## 통계 vs. Machine Learning\n\n-   통계는 과거를 통해 대표값을 얻는 것. e.g., 평균. 머신라닝은 과거를 통해 미래를 예측하고 인사이트를 찾는 것.\n\n-   표본: 다수에서 소수를 뽑고 대표값을 구하는 것\n\n## Deep Learning\n\n-   다른 머신러닝 기법들과 차이점. Nonlinear function을 풀기 휘애 NONLINEAR FUNCTION을 linear function의 결합으로. -\\> 엄청 복잡한 함수(인공지능)를 만들 수 있다.\n\n-   다층 레이어(Multiple layer)\n\n-   Hidden layer가 2개 이상인 NN(Neural Network)을 Deep Learning이라고 부른다.\n\n## Linear function vs. Nonlinear function\n\n-   선형회귀 모델은 '회귀계수(regression coefficient)를 선형 결합으로 표현할 수 있는 모델'\n\n-   계수들과 변수의 곱셈과 그들의 덧셈과 뺄셈으ㅗㄹ만 결합되어 있는 것을 의미한다.\n\n-   독립변수가 일차식인지, 이차식인지, 로그함수인지가 중요한 것이 아니라 추정할 대사인 파라미터가 어떻게 생겼느냐의 문제.\n\n-   y = a0 + a1x1, y = a0+a1x1+a2x2 등은 선형회귀식.\n\n-   비선형회귀 모델은 데이터를 어떻게 변형하더라도 파라미터를 선형결합식으로 표현할 수 없는 모델.\n\n-   선형회귀모델은 파라미터 계수에 대한 해석이 단순하지만, 비선형 모델은 형태가 복잡할 경우 해석하기 어렵기 때문에 통계 모델에서는 비선형회귀 모델을 잘 사용하지 않는다.\n\n## Machine Learning은 문제 해결을 위한 함수 f()를 찾는 것이다.\n\n-   종속변수(y)를 독립변수(x)들의 함수 f(x)로 적합. Y =f(x)\n\n    -   독립변수!!! x1, x2, x3, x4, ... 독립볍수가 아니라면 전처리를 해야 함\n\n-   f(함수)가 무엇일까? 문제를 풀 방법? 분석방법을 의미한다.\n\n-   예제 1) Sales prediction : 특정 고객 -\\> 마케핑 캠패인에 반응할 확률\n\n    -   x : 고객 과거 data, 캠페인 요소들\n\n    -   y : 반응할 확률 -\\> 캠패인을 확인한 사람에게 세일즈를 하는 것이 좋다.\n\n-   예제 2) 휴대폰 고객이 향후 6개월 이내에 이탈할 확률\n\n    -   x : 휴대폰 고객, y : 이탈할 확률\n\n-   예제 3) y: 다음 주 주가상승 여부 =f(x :최근 주가 추이, 환경분석)\n\n## 머신러닝 모델링 프로세스\n\n1.  문제 정의 및 명확한 목표 설정\n2.  데이터 수집 (including Random Sampling)\n3.  데이터 탐색, Cleaning, Pre-processing\n4.  데이터 분류 및 데이터 세닝\n    -   Training set, Validation set, Testing set 으로 구분\n5.  데이터 방법론 선택\n    -   Regression, Classification, Clustering, Recommender 등 선택\n    -   regression은 원인과 결과를 찾는 데 쓸 수 있는데, 상관관계는 correlation. 다르다.\n6.  구체적인 기술 및 평가 방법 선택\n    -   Linear Regression, Logistic Regression, Decision tree, Random Forest, KNN, K-means, Matrix Factorization\n7.  테스트 및 튜닝\n8.  결과 및 모델 비교\n9.  모델 선택 및 적용\n\n# Week 4\n\n## Regression(회귀)\n\n-   Regression -\\> 원인과 결과를 분석하는데 쓰임. y= ax1+bx2+cx3+d 와 같은 회귀식을 도출한다.\n\n-   똘똘한 기울기와 절편을 구하는 것. 기울기 = 가중치, 절편 = 편향.\n\n### 선형회귀\n\n-   가장 훌륭한 선 긋기 -\\> 머신러닝은 미래의 방향을 설정하는 것에서 부터 시작. y = ax+b로 표현될 수 있으며, x값이 변함에 따라 y 값도 변한다. Simple linear regression. 예, 독립변수 x가 공부한 시간, 성적 y를 예측할 경우, x가 한 개 이므로, simple linear regression.\n\n-   가장 정확한 기울기 a와 절편 b를 찾으면 된다.\n\n-   여러가지 선을 그을 수 있고, 여러가지 선 중, 반복되는 선 긋기를 통해 가장 훌륭한 선을 찾는다.\n\n-   선형회귀는 임의의 직선을 그어 이에 대한 평균제곱오차를 구하고, 이 값을 가장 작게 만들어주는 a와 b를 찾아가는 작업.\n\n-   어떻게 훌륭한 선을 찾을까? 오차(예측값 - 실제값) 줄이기\n\n-   예측모델 성능 평가\n\n    -   가장 많이 쓰는 방법: **평균 제곱 오차(MSE: Mean Square Error)**\n\n    -   **평균 제곱근 오차(RMSE: Root Mean Square Error)** : MSE 값은 오류의 제곱을 구하므로, 실제 오류의 푱균보다 값이 더 커질 수 있어, MSE 에 루트를 씌운 경우\n\n    -   **평균절대오차(MAE: Mean Absolute Error**)\n\n-   모든 것을 정확히 고려하면 overfitting이 될 수 있다.\n\n-   선형은 직선을 의미하는 것이 아니라 계수들의 곱과 합을로 이루어진 것을 말함.\n\n-   \n\n-   예재로 배우기 : 집값 예측\n\n    -   최근 주변 부동산 시세를 살펴본다. 보통 얼마에 거래되었을까?\n\n    -   방법: 여러가지 특징 세트가 있을 때 특정 변화에 따라 output(y)의 변화를 살펴본다.\n\n-   **(로지스틱 회귀)** 전달받은 정보를 놓고 참과 거짓 중 하나를 Output으로 선택하는 방법론. 참/거짓 판단장치라고 하며, 이진 분류에 많이 사용함. 예제) 합격자 발표에서 점수화 상관없이 '합격' 불합격'만 존재합니다.\n\n## 실습\n\n-   python 설치. Terminal.\n\n    ::: callout-note\n    py -m pip install jupyter\n    :::\n\n    ::: callout-note\n    ```         \n    python -m pip install jupyter\n    ```\n\n    -   pip install pandas\n\n    -   pip install numpy\n\n    -   pip install matplotlib\n\n    -   pip install seaborn\n    :::\n\n    python3 -m pip install matplotlib\n\n-   \n\n-   \n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\n```\n:::\n\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nimport pandas as pd ### 데이터 분석을 하기 위한 파이썬 라이브러리 such as a table\nimport numpy as np ### 수치해석 라이브러리\nimport matplotlib.pyplot as plt ### 그래프 그리는 라이브러리\nimport seaborn as sns ### 그래프 그리는 라이브러리\n```\n:::\n\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nr = np.arange(0, 2, 0.01)\ntheta = 2 * np.pi * r\nfig, ax = plt.subplots(\n  subplot_kw = {'projection': 'polar'} \n)\nax.plot(theta, r)\nax.set_rticks([0.5, 1, 1.5, 2])\nax.grid(True)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![A line plot on a polar axis](ITM812_files/figure-html/fig-polar-output-1.png){#fig-polar width=450 height=439}\n:::\n:::\n\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\ndf=pd.read_csv(\"./ITM812/BostonHousing2.csv\")\n```\n:::\n\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\n#데이터셋을 불러와서 첫 세 줄을 출력하여 데이터의 구성을 한 번 살펴볼게요.\ndf.tail(10)\n#df.tail(3)\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TOWN</th>\n      <th>LON</th>\n      <th>LAT</th>\n      <th>CMEDV</th>\n      <th>CRIM</th>\n      <th>ZN</th>\n      <th>INDUS</th>\n      <th>CHAS</th>\n      <th>NOX</th>\n      <th>RM</th>\n      <th>AGE</th>\n      <th>DIS</th>\n      <th>RAD</th>\n      <th>TAX</th>\n      <th>PTRATIO</th>\n      <th>B</th>\n      <th>LSTAT</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>496</th>\n      <td>Revere</td>\n      <td>-71.0010</td>\n      <td>42.2525</td>\n      <td>19.7</td>\n      <td>0.28960</td>\n      <td>0.0</td>\n      <td>9.69</td>\n      <td>0</td>\n      <td>0.585</td>\n      <td>5.390</td>\n      <td>72.9</td>\n      <td>2.7986</td>\n      <td>6</td>\n      <td>391</td>\n      <td>19.2</td>\n      <td>396.90</td>\n      <td>21.14</td>\n    </tr>\n    <tr>\n      <th>497</th>\n      <td>Revere</td>\n      <td>-70.9947</td>\n      <td>42.2496</td>\n      <td>18.3</td>\n      <td>0.26838</td>\n      <td>0.0</td>\n      <td>9.69</td>\n      <td>0</td>\n      <td>0.585</td>\n      <td>5.794</td>\n      <td>70.6</td>\n      <td>2.8927</td>\n      <td>6</td>\n      <td>391</td>\n      <td>19.2</td>\n      <td>396.90</td>\n      <td>14.10</td>\n    </tr>\n    <tr>\n      <th>498</th>\n      <td>Revere</td>\n      <td>-71.0050</td>\n      <td>42.2455</td>\n      <td>21.2</td>\n      <td>0.23912</td>\n      <td>0.0</td>\n      <td>9.69</td>\n      <td>0</td>\n      <td>0.585</td>\n      <td>6.019</td>\n      <td>65.3</td>\n      <td>2.4091</td>\n      <td>6</td>\n      <td>391</td>\n      <td>19.2</td>\n      <td>396.90</td>\n      <td>12.92</td>\n    </tr>\n    <tr>\n      <th>499</th>\n      <td>Revere</td>\n      <td>-70.9985</td>\n      <td>42.2430</td>\n      <td>17.5</td>\n      <td>0.17783</td>\n      <td>0.0</td>\n      <td>9.69</td>\n      <td>0</td>\n      <td>0.585</td>\n      <td>5.569</td>\n      <td>73.5</td>\n      <td>2.3999</td>\n      <td>6</td>\n      <td>391</td>\n      <td>19.2</td>\n      <td>395.77</td>\n      <td>15.10</td>\n    </tr>\n    <tr>\n      <th>500</th>\n      <td>Revere</td>\n      <td>-70.9920</td>\n      <td>42.2380</td>\n      <td>16.8</td>\n      <td>0.22438</td>\n      <td>0.0</td>\n      <td>9.69</td>\n      <td>0</td>\n      <td>0.585</td>\n      <td>6.027</td>\n      <td>79.7</td>\n      <td>2.4982</td>\n      <td>6</td>\n      <td>391</td>\n      <td>19.2</td>\n      <td>396.90</td>\n      <td>14.33</td>\n    </tr>\n    <tr>\n      <th>501</th>\n      <td>Winthrop</td>\n      <td>-70.9860</td>\n      <td>42.2312</td>\n      <td>22.4</td>\n      <td>0.06263</td>\n      <td>0.0</td>\n      <td>11.93</td>\n      <td>0</td>\n      <td>0.573</td>\n      <td>6.593</td>\n      <td>69.1</td>\n      <td>2.4786</td>\n      <td>1</td>\n      <td>273</td>\n      <td>21.0</td>\n      <td>391.99</td>\n      <td>9.67</td>\n    </tr>\n    <tr>\n      <th>502</th>\n      <td>Winthrop</td>\n      <td>-70.9910</td>\n      <td>42.2275</td>\n      <td>20.6</td>\n      <td>0.04527</td>\n      <td>0.0</td>\n      <td>11.93</td>\n      <td>0</td>\n      <td>0.573</td>\n      <td>6.120</td>\n      <td>76.7</td>\n      <td>2.2875</td>\n      <td>1</td>\n      <td>273</td>\n      <td>21.0</td>\n      <td>396.90</td>\n      <td>9.08</td>\n    </tr>\n    <tr>\n      <th>503</th>\n      <td>Winthrop</td>\n      <td>-70.9948</td>\n      <td>42.2260</td>\n      <td>23.9</td>\n      <td>0.06076</td>\n      <td>0.0</td>\n      <td>11.93</td>\n      <td>0</td>\n      <td>0.573</td>\n      <td>6.976</td>\n      <td>91.0</td>\n      <td>2.1675</td>\n      <td>1</td>\n      <td>273</td>\n      <td>21.0</td>\n      <td>396.90</td>\n      <td>5.64</td>\n    </tr>\n    <tr>\n      <th>504</th>\n      <td>Winthrop</td>\n      <td>-70.9875</td>\n      <td>42.2240</td>\n      <td>22.0</td>\n      <td>0.10959</td>\n      <td>0.0</td>\n      <td>11.93</td>\n      <td>0</td>\n      <td>0.573</td>\n      <td>6.794</td>\n      <td>89.3</td>\n      <td>2.3889</td>\n      <td>1</td>\n      <td>273</td>\n      <td>21.0</td>\n      <td>393.45</td>\n      <td>6.48</td>\n    </tr>\n    <tr>\n      <th>505</th>\n      <td>Winthrop</td>\n      <td>-70.9825</td>\n      <td>42.2210</td>\n      <td>19.0</td>\n      <td>0.04741</td>\n      <td>0.0</td>\n      <td>11.93</td>\n      <td>0</td>\n      <td>0.573</td>\n      <td>6.030</td>\n      <td>80.8</td>\n      <td>2.5050</td>\n      <td>1</td>\n      <td>273</td>\n      <td>21.0</td>\n      <td>396.90</td>\n      <td>7.88</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n",
    "supporting": [
      "ITM812_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}